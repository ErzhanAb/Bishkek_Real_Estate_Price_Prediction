# Прогноз стоимости квартир в Бишкеке

## Описание проекта

Этот проект — интеллектуальная система для оценки стоимости недвижимости в Бишкеке с помощью ансамбля моделей машинного обучения.

Сервис предсказывает цену квартиры на основе её характеристик и координат, а также выводит 95% эмпирические доверительные интервалы для более точной оценки.

Модели развернуты в виде веб-приложения на [Hugging Face Spaces (Gradio)](https://huggingface.co/spaces/ErzhanAb/Bishkek_Real_Estate_Price_Prediction_Competition)

## Как готовились данные

**Источник данных:** объявления о продаже квартир в Бишкеке (house.kg). Всего 7134 объектов.

### Очистка и обработка данных:

- Извлечение новых признаков из исходных данных, например: преобразование текстовых полей, расчет дополнительных категорий, кластеризация по координатам.
- Удаление строк с пропущенными значениями по ключевым признакам: площадь, количество комнат, этаж, координаты.
- Удаление большого количества признаков, в которых было слишком много пропусков или которые показывали слабую связь с таргетом (например, по низкой важности в feature importance или по корреляции).
- Удаление выбросов по цене (например, квартиры с площадью 50 м² по цене $500 000).
- Добавлен новый признак `hdbscan_cluster` — кластеризация локаций по алгоритму HDBSCAN (широта/долгота).
- Преобразование категориальных признаков через `OneHotEncoder`.
- Количество объектов уменьшено с 7134 до 7126 объектов.

### Удаление объектов с аномальными значениями:

- Использовалась предварительная модель `LinearRegression` для удаления квартир, где ошибка предсказания превышала ±20 000 USD для SGDRegressor.

## Обученные модели (3 модели)

### CatBoostRegressor 

- Основная модель: CatBoost с оптимизированными гиперпараметрами (Optuna).
- Эмпирический доверительный интервал: отдельно обученные модели для квантилей 2.5% и 97.5%.
- Категориальные признаки используются напрямую, без OneHotEncoding.

### RandomForestRegressor

- RandomForest с гиперпараметрами, подобранными через Optuna.
- Эмпирический доверительный интервал рассчитывается по всем деревьям ансамбля (бутстрэп по деревьям).

### SGDRegressor + Bagging

- Основной `SGDRegressor` в пайплайне с `OneHotEncoder` и `StandardScaler`.
- Отдельный `BaggingRegressor` на основе `SGDRegressor` для расчета эмпирического доверительного интервала.
- Перед обучением были удалены объекты, где ошибка по `LinearRegression` превышала ±20 000 USD.

## Анализ моделей

- Все модели проходили 5-кратную кросс-валидацию.
- Оценивались метрики:

  - R²
  - MAE
  - MAPE

- Для `SGDRegressor` дополнительно анализировались коэффициенты признаков.
- Для `RandomForest` и `CatBoost` использовались `feature_importances_`.

## Гетероскедастичность

В данных наблюдается гетероскедастичность — дисперсия ошибки меняется в зависимости от площади, количества комнат и локации.

## CatBoostRegressor

![CatBoost](https://github.com/ErzhanAb/Bishkek_Real_Estate_Price_Prediction/blob/main/images/het_catboost.png)

## RandomForestRegressor

![RF](https://github.com/ErzhanAb/Bishkek_Real_Estate_Price_Prediction/blob/main/images/het_rf.png)

## SGDRegressor

![SGD](https://github.com/ErzhanAb/Bishkek_Real_Estate_Price_Prediction/blob/main/images/het_sgd.png)

### Как это решается:

- Квантильная регрессия (CatBoost с квантилями).
- Бутстрэп по деревьям (RandomForest).
- Бутстрэп по моделям (SGD + Bagging).

## Структура проекта

- **app.py**
- **CatBoostRegressor_model.pkl**
- **CatBoost_lower.pkl**
- **CatBoost_upper.pkl**
- **RandomForestRegressor_model.pkl**
- **SGDRegressor_model.pkl**
- **SGD_BaggingInterval.pkl**
- **hdbscan_model.pkl**
- **category_options.pkl**
- **knn_model.pkl**
- **scaler_knn.pkl**
- **knn_columns.pkl**
- **y_train.pkl**
- **requirements.txt**
- **README.md**

## Как развернуть проект на Hugging Face Spaces

**Шаги для запуска:**

- Создайте Space с типом Gradio.
- Загрузите все файлы проекта, включая обученные модели (`.pkl` файлы).
- Создайте файл `requirements.txt` со следующим содержимым:

  - **gradio**
  - **catboost**
  - **scikit-learn==1.6.1**
  - **numpy**
  - **pandas**
  - **joblib**
  - **hdbscan**

- Запустите проект. Hugging Face автоматически выполнит `app.py`.

## Входные признаки модели

На вход всех моделей подаются следующие признаки:

| Признак           | Описание                                                                        |
|-------------------|---------------------------------------------------------------------------------|
| `room_count`      | Количество комнат                                                               |
| `lat`             | Широта (latitude) — географическая координата                                   |
| `lon`             | Долгота (longitude) — географическая координата                                 |
| `Серия`           | Серия дома (например, "104", "хрущевка")                           |
| `house_material`  | Материал стен (например, "кирпичный", "панельный", "монолитный")                 |
| `floor`           | Этаж квартиры                                                                   |
| `total_floors`    | Общее количество этажей в доме                                                  |
| `total_area`      | Общая площадь квартиры (в квадратных метрах)                                    |
| `Отопление`       | Тип отопления (например, "центральное")                               |
| `Состояние`       | Состояние квартиры (например, "евроремонт")                  |
| `hdbscan_cluster` | Кластер, определенный алгоритмом HDBSCAN на основе координат (lat, lon)         |


## Как определяется кластер?

Кластеризация по координатам позволяет учитывать особенности районов (центральные, спальные, окраины).

*   Кластеры формируются автоматически с помощью HDBSCAN на основе `lat` и `lon`.
*   При вводе новых данных кластер назначается через предобученную модель `hdbscan_model.pkl`.

## category_options.pkl

Файл `category_options.pkl` содержит словарь со всеми уникальными значениями категориальных признаков:

- **"Серия"** — тип серии дома.
- **"house_material"** — материал стен.
- **"Отопление"** — тип отопления.
- **"Состояние"** — состояние квартиры.

Этот файл используется для создания удобных Dropdown-меню в интерфейсе Gradio.

## Использование HDBSCAN и категорий в инференсе

При вводе новых данных пользователем:

- Определяется кластер с помощью `hdbscan_model.pkl`.
- Категориальные признаки выбираются из `category_options.pkl` для корректного `OneHotEncoding` и валидации ввода.

## SGD models

Этот релиз включает:
*   **SGDRegressor** — линейная модель с градиентным спуском для основной оценки стоимости.
*   **BaggingRegressor на основе SGD** — для расчета доверительного интервала (бутстрэп по моделям).

## Подготовка данных

Перед обучением проводилась фильтрация по ошибкам `LinearRegression`:
*   Была обучена предварительная модель `LinearRegression`.
*   Удалены объекты, где ошибка предсказания превышала ±20 000 USD.

Это позволило избавиться от сильных выбросов и стабилизировать обучение линейной модели.

**Объем данных:**
*   **До фильтрации:** 7126 объектов
*   **После фильтрации:** 5394 объектов

## Обучение модели

**Признаки:**
*   **Категориальные признаки:** `OneHotEncoder`
*   **Числовые признаки:** `StandardScaler`
*   **Модель:** `SGDRegressor`

**Подбор гиперпараметров:** Optuna

**Используемые параметры SGD:**
*   `learning_rate`: 'constant'
*   `penalty`: 'l1'
*   `alpha`: 2.1591826223410696e-05
*   `eta0`: 0.02
*   `power_t`: 0.2
*   `epsilon`: 50
*   `max_iter`: 1500

## Эмпирический доверительный интервал

Для расчета эмпирического доверительного интервала использован:
*   `BaggingRegressor` с 100 моделями `SGDRegressor`.
*   Бустрэп по подвыборкам для оценки неопределенности.

## Метрики

**5-кратная кросс-валидация (после фильтрации выбросов):**
*   **R²:** 0.9515
*   **MAE:** 7933.97 USD
*   **MAPE:** 0.0943

**На обучении (train):**
*   **R²:** 0.9511
*   **MAE:** 8129.58 USD
*   **MAPE:** 0.0998

## Интерпретация коэффициентов

Все коэффициенты доступны по признакам и категориям.

Признаки обрабатывались через `OneHotEncoder`, поэтому категории имеют отдельные веса.

Для анализа важности учитывались не абсолютные значения, а реальные коэффициенты (с плюсом/минусом).

Линейная модель показывает не только связь с ценой, но и косвенное влияние связанной информации (например, материал дома может быть связан с районом и площадью).

![График коэффициентов признаков](https://github.com/ErzhanAb/Bishkek_Real_Estate_Price_Prediction/releases/download/SGD/SGD_Coefficients.png)

## Особенности

*   Модель линейная, поэтому чувствительна к выбросам — фильтрация обязательна.
*   Используется простая и быстрая архитектура, которая легко интерпретируется.
*   `Bagging` позволяет дополнить модель эмпирическим доверительным интервалом.

## RandomForest model

В этом релизе представлена модель `RandomForestRegressor` для предсказания стоимости квартир в Бишкеке.

**Особенности:**
*   **Основная модель:** `RandomForestRegressor_model.pkl`
*   Эмпирический доверительный интервал считается по бутстрэпу деревьев (используются предсказания всех деревьев ансамбля).

## Как обучалась модель

Гиперпараметры подбирались с помощью Optuna.

**Используемые параметры:**
*   `n_estimators`: 485
*   `max_depth`: 19
*   `min_samples_split`: 2
*   `min_samples_leaf`: 1
*   `max_features`: None
*   `bootstrap`: True

### Подготовка данных
*   Категориальные признаки обрабатывались через `OneHotEncoder`.
*   Числовые признаки — через `StandardScaler`.
*   Модель обернута в `Pipeline` для удобства инференса.

## Кросс-валидация (5-Fold)

Средние метрики на валидации:

| Метрика | Значение         |
|---------|------------------|
| R²      | 0.9073           |
| MAE     | 12 020.07 USD    |
| MAPE    | 9.83%            |

## Метрики на Train

| Метрика | Значение         |
|---------|------------------|
| R²      | 0.9872           |
| MAE     | 4 706.72 USD     |
| MAPE    | 3.93%            |

## Feature Importance

![Важность признаков для RandomForest](https://github.com/ErzhanAb/Bishkek_Real_Estate_Price_Prediction/releases/download/RandomForest/feature_importance_randomforest.png)

## Эмпирический доверительный интервал

Эмпирический доверительный интервал считается по всем деревьям ансамбля.
Для каждого объекта берутся все предсказания от деревьев, затем вычисляются:
*   **Среднее значение** (основной прогноз)
*   **2.5-й перцентиль** — нижняя граница интервала
*   **97.5-й перцентиль** — верхняя граница интервала

## CatBoost models

В этом релизе представлены 3 модели на основе CatBoost для предсказания стоимости квартир в Бишкеке:

*   **Основная модель:** `CatBoostRegressor_model.pkl`
    *   Предсказывает медианную цену квартиры.

*   **Квантильные модели:**
    *   `CatBoost_lower.pkl` — нижняя граница 95% эмпирического доверительного интервала (2.5-й перцентиль).
    *   `CatBoost_upper.pkl` — верхняя граница 95% эмпирического доверительного интервала (97.5-й перцентиль).

## Как обучалась модель

Оптимизация гиперпараметров проводилась с помощью Optuna.

**Используемые параметры:**
*   `iterations`: 665
*   `depth`: 14
*   `learning_rate`: 0.0427
*   `l2_leaf_reg`: 14.38
*   `random_strength`: 0.315
*   `bagging_temperature`: 0.321
*   `border_count`: 227
*   `grow_policy`: Depthwise
*   `min_data_in_leaf`: 17
*   `loss_function`: MAE (для основной модели)

### Квантильные модели

Для эмпирических доверительных интервалов использовались те же параметры, но с другими функциями потерь:

*   **Для нижней границы интервала:**
    `loss_function = 'Quantile:alpha=0.025'`

*   **Для верхней границы интервала:**
    `loss_function = 'Quantile:alpha=0.975'`

Категориальные признаки передавались напрямую в CatBoost через параметр `cat_features`, без `OneHotEncoding`.

## Кросс-валидация (5-Fold)

Средние метрики на валидации:

| Метрика | Значение        |
|---------|-----------------|
| R²      | 0.9112          |
| MAE     | 11 485.29 USD   |
| MAPE    | 9.13%           |

## Метрики на Train

| Метрика | Значение        |
|---------|-----------------|
| R²      | 0.9671          |
| MAE     | 5 709.68 USD    |
| MAPE    | 4.36%           |

## Feature Importance

![Важность признаков для CatBoost](https://github.com/ErzhanAb/Bishkek_Real_Estate_Price_Prediction/releases/download/CatBoost/feature_importance_catboost.png)

## Особенности

*   Модель учитывает географические кластеры (`HDBSCAN`) для автоматического разделения города на районы по плотности точек.
*   Квантильные модели позволяют получать не только медианное предсказание, но и 95% эмпирический доверительный интервал.

## KNN модель (поиск ближайших аналогов)

В проект также интегрирован поиск ближайших аналогов (KNN) для дополнительной интерпретации результатов.

## Для чего это нужно?

KNN используется для наглядного вывода:

*   Цен соседей-аналогов для выбранной квартиры.
*   Среднего значения по соседям.
*   95% эмпирического интервала по ближайшим объектам.
*   Графического сравнения (гистограмма + линии).

Это позволяет пользователю понять, какие реальные цены были у похожих объектов из обучающей выборки.

## Как работает KNN:

*   Используется масштабирование признаков через `StandardScaler` (чтобы признаки были в одном масштабе).
*   Категориальные признаки кодируются через `OneHotEncoder`.
*   Дополнительно используется признак `hdbscan_cluster` (кластер по координатам).

### Динамическое количество соседей:

В зависимости от сегмента выбирается разное `k`:

| Диапазон цены (CatBoost предсказание) | Количество соседей (k) |
|---------------------------------------|------------------------|
| ≤ 100 000 USD                         | 30                     |
| 100 000 – 250 000 USD                 | 20                     |
| 250 000 – 400 000 USD                 | 10                     |
| > 400 000 USD                         | 5                      |

Это сделано для учета гетероскедастичности — на дорогих квартирах меньше аналогов, поэтому `k` уменьшается.

### Что сохраняется для KNN:

*   `knn_model.pkl` — обученный NearestNeighbors
*   `scaler_knn.pkl` — StandardScaler для числовых признаков
*   `knn_columns.pkl` — список признаков, участвующих в KNN (с учетом OneHotEncoding)
*   `y_train.pkl` — таргет для поиска аналогов (цены квартир в обучающей выборке)

## Визуализация:

При инференсе в приложении на Hugging Face автоматически строится график:

*   Гистограмма цен ближайших соседей
*   Линия CatBoost предсказания
*   Среднее по KNN
*   95% интервал по KNN

Это дает пользователю дополнительные ориентиры по рынку.
